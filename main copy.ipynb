{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n",
      "Training Started...\n",
      "Epoch [1/10], Train Loss: 0.3629, Val Loss: 0.3171\n",
      "Epoch [2/10], Train Loss: 0.2935, Val Loss: 0.2839\n",
      "Epoch [3/10], Train Loss: 0.2610, Val Loss: 0.2515\n",
      "Epoch [4/10], Train Loss: 0.2428, Val Loss: 0.2414\n",
      "Epoch [5/10], Train Loss: 0.2274, Val Loss: 0.2649\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    138\u001b[0m     model \u001b[38;5;241m=\u001b[39m MarineDebrisClassifier(numBands\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 139\u001b[0m     \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumEpochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearningRate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     testPredictions \u001b[38;5;241m=\u001b[39m inference(model, testLoader)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestPredictions[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 102\u001b[0m, in \u001b[0;36mtrainModel\u001b[0;34m(model, trainLoader, valLoader, numEpochs, learningRate)\u001b[0m\n\u001b[1;32m    100\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    101\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Apply sigmoid, labels expect single-channel\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    104\u001b[0m runningLoss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dataset Class\n",
    "class MarineDebrisDataset(Dataset):\n",
    "    def __init__(self, folderPath, transform=None):\n",
    "        self.folderPath = folderPath\n",
    "        self.fileNames = [f for f in os.listdir(folderPath) if f.endswith('.pkl')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fileNames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filePath = os.path.join(self.folderPath, self.fileNames[idx])\n",
    "        with open(filePath, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        \n",
    "        image = data[0]\n",
    "        label = data[1]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Data Augmentation and Transformations\n",
    "transformTrain = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5] * 12, std=[0.2] * 12)\n",
    "])\n",
    "\n",
    "transformTest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5] * 12, std=[0.2] * 12)\n",
    "])\n",
    "\n",
    "# Initialize datasets\n",
    "trainDataset = MarineDebrisDataset(folderPath=\"classification_dataset/train\", transform=transformTrain)\n",
    "valDataset = MarineDebrisDataset(folderPath=\"classification_dataset/validation\", transform=transformTest)\n",
    "testDataset = MarineDebrisDataset(folderPath=\"classification_dataset/test\", transform=transformTest)\n",
    "\n",
    "# Handle class imbalance\n",
    "trainLabels = []\n",
    "for _, label in trainDataset:\n",
    "    trainLabels.append(int(label))\n",
    "\n",
    "classCounts = np.bincount(trainLabels)\n",
    "classWeights = 1.0 / classCounts\n",
    "sampleWeights = [classWeights[label] for label in trainLabels]\n",
    "sampler = WeightedRandomSampler(sampleWeights, len(trainDataset))\n",
    "\n",
    "# DataLoaders\n",
    "trainLoader = DataLoader(trainDataset, batch_size=32, sampler=sampler)\n",
    "valLoader = DataLoader(valDataset, batch_size=32, shuffle=False)\n",
    "testLoader = DataLoader(testDataset, batch_size=32, shuffle=False)\n",
    "print(\"Loaded data\")\n",
    "# Model Definition\n",
    "class MarineDebrisClassifier(nn.Module):\n",
    "    def __init__(self, numBands):\n",
    "        super(MarineDebrisClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=numBands, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (4, 4))  # Downsample feature map\n",
    "        x = x.view(-1, 256 * 4 * 4)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Training Function\n",
    "def trainModel(model, trainLoader, valLoader, numEpochs, learningRate):\n",
    "    print(\"Training Started...\")\n",
    "    criterion = nn.BCELoss()  # Binary cross-entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
    "    bestValLoss = float('inf')\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        model.train()\n",
    "        runningLoss = 0.0\n",
    "        for inputs, labels in trainLoader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # Apply sigmoid, labels expect single-channel\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            runningLoss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        valLoss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valLoader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.unsqueeze(1))\n",
    "                valLoss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{numEpochs}], Train Loss: {runningLoss/len(trainLoader):.4f}, Val Loss: {valLoss/len(valLoader):.4f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if valLoss < bestValLoss:\n",
    "            bestValLoss = valLoss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Inference Function\n",
    "def inference(model, testLoader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in testLoader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    model = MarineDebrisClassifier(numBands=12).to(device)\n",
    "    trainModel(model, trainLoader, valLoader, numEpochs=10, learningRate=1e-3)\n",
    "    testPredictions = inference(model, testLoader)\n",
    "    print(f\"Sample Predictions: {testPredictions[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluateModel(model, dataLoader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    model.eval()\n",
    "    allPredictions = []\n",
    "    allLabels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataLoader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # Collect predictions and labels\n",
    "            allPredictions.extend(predictions.cpu().numpy())\n",
    "            allLabels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Check if all classes are present in predictions\n",
    "    predictedClasses = set(allPredictions)\n",
    "    trueClasses = set(allLabels)\n",
    "    missingClasses = trueClasses - predictedClasses\n",
    "    if missingClasses:\n",
    "        print(f\"Warning: The model did not predict the following classes: {missingClasses}\")\n",
    "    \n",
    "    # Compute metrics with zero_division set to 0\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(\n",
    "        allLabels, \n",
    "        allPredictions, \n",
    "        target_names=[\"No Debris\", \"Debris\"], \n",
    "        zero_division=0\n",
    "    ))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(allLabels, allPredictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Debris\", \"Debris\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "evaluateModel(model, testLoader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
